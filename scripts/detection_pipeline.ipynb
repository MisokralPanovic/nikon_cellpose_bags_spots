{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f29d9c7",
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "/home/michalv/miniforge3/envs/cellpose-bags/lib/python3.11/site-packages/cv2/python-3.11/../../../../libopencv_imgcodecs.so.411: undefined symbol: _ZN7Imf_3_36HeaderC1EiifRKN9Imath_3_14Vec2IfEEfNS_9LineOrderENS_11CompressionE",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mImportError\u001b[39m                               Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[1]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnumpy\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mas\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnp\u001b[39;00m\n\u001b[32m      2\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mskimage\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mcv2\u001b[39;00m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mnd2\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mxarray\u001b[39;00m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cellpose-bags/lib/python3.11/site-packages/cv2/__init__.py:181\u001b[39m\n\u001b[32m    176\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mExtra Python code for\u001b[39m\u001b[33m\"\u001b[39m, submodule, \u001b[33m\"\u001b[39m\u001b[33mis loaded\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    178\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[33m'\u001b[39m\u001b[33mOpenCV loader: DONE\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m181\u001b[39m bootstrap()\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cellpose-bags/lib/python3.11/site-packages/cv2/__init__.py:153\u001b[39m, in \u001b[36mbootstrap\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    149\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m DEBUG: \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mRelink everything from native cv2 module to cv2 package\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    151\u001b[39m py_module = sys.modules.pop(\u001b[33m\"\u001b[39m\u001b[33mcv2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m153\u001b[39m native_module = importlib.import_module(\u001b[33m\"\u001b[39m\u001b[33mcv2\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    155\u001b[39m sys.modules[\u001b[33m\"\u001b[39m\u001b[33mcv2\u001b[39m\u001b[33m\"\u001b[39m] = py_module\n\u001b[32m    156\u001b[39m \u001b[38;5;28msetattr\u001b[39m(py_module, \u001b[33m\"\u001b[39m\u001b[33m_native\u001b[39m\u001b[33m\"\u001b[39m, native_module)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/miniforge3/envs/cellpose-bags/lib/python3.11/importlib/__init__.py:126\u001b[39m, in \u001b[36mimport_module\u001b[39m\u001b[34m(name, package)\u001b[39m\n\u001b[32m    124\u001b[39m             \u001b[38;5;28;01mbreak\u001b[39;00m\n\u001b[32m    125\u001b[39m         level += \u001b[32m1\u001b[39m\n\u001b[32m--> \u001b[39m\u001b[32m126\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m _bootstrap._gcd_import(name[level:], package, level)\n",
      "\u001b[31mImportError\u001b[39m: /home/michalv/miniforge3/envs/cellpose-bags/lib/python3.11/site-packages/cv2/python-3.11/../../../../libopencv_imgcodecs.so.411: undefined symbol: _ZN7Imf_3_36HeaderC1EiifRKN9Imath_3_14Vec2IfEEfNS_9LineOrderENS_11CompressionE"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import skimage\n",
    "import cv2\n",
    "import nd2\n",
    "import xarray\n",
    "from aicspylibczi import CziFile\n",
    "from aicsimageio import AICSImage\n",
    "import gc\n",
    "\n",
    "# DL frameworks\n",
    "from cellpose import models\n",
    "from spotiflow.model import Spotiflow\n",
    "\n",
    "# figures\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "# plotting and processing\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "experiment_folder = Path.cwd().parent \n",
    "raw_data_folder = experiment_folder / 'raw_data'\n",
    "figures_folder = experiment_folder / 'figures'\n",
    "processed_data_folder = experiment_folder / 'processed_data'\n",
    "os.environ[\"CELLPOSE_LOCAL_MODELS_PATH\"] = str(experiment_folder.parent / '_pipeline_assets/cellpose_models/') # location of cellpose models\n",
    "\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "figures_folder.mkdir(exist_ok=True)\n",
    "processed_data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# ANALYSIS PARAMETERS\n",
    "thickness_um = 20\n",
    "\n",
    "# Channel order\n",
    "channels_params = {\n",
    "    'brightfield': 0,\n",
    "    'spots': 1,\n",
    "    'bags': 2\n",
    "}\n",
    "\n",
    "# Segmentation parameters\n",
    "segmentation_params = {\n",
    "    'model_name': 'cpsam_20x_downsampeled_20250630',\n",
    "    'downsample_factor': 0.1\n",
    "}\n",
    "\n",
    "footprint = np.array([\n",
    "    [1,0,1,0,1],\n",
    "    [0,1,1,1,0],\n",
    "    [1,1,1,1,1],\n",
    "    [0,1,1,1,0],\n",
    "    [1,0,1,0,1]\n",
    "], dtype=bool)\n",
    "\n",
    "print(f\"Experiment folder: {experiment_folder}\")\n",
    "print(f\"Gel thickness: {thickness_um} Î¼m\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a189a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "def stdev_project_xarray(array):\n",
    "    \"\"\"Standard deviation projection of single xarray channel\"\"\"\n",
    "    return np.std(array.values, axis=0)\n",
    "\n",
    "def process_field_of_view(array, p, channels_params):\n",
    "    seg_data = array.isel(P=p, C=channels_params['brightfield'])\n",
    "    spots_data = array.isel(P=p, C=channels_params['spots'])\n",
    "    \n",
    "    seg_projected = stdev_project_xarray(seg_data)\n",
    "    del seg_data\n",
    "    \n",
    "    spots_projected = stdev_project_xarray(spots_data)\n",
    "    del spots_data\n",
    "    \n",
    "    return seg_projected, spots_projected\n",
    "\n",
    "# segmentation\n",
    "def cellpose_bag(image):\n",
    "    \"\"\"Run bag pretrained cellpose SAM\"\"\"\n",
    "    model = models.CellposeModel(\n",
    "        gpu=True,\n",
    "        pretrained_model=segmentation_params['model_name']\n",
    "    )\n",
    "    \n",
    "    masks, flows, styles = model.eval(\n",
    "        image\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "def downsample(image: np.ndarray, scale_factor: float) -> np.ndarray:\n",
    "    if not 0.0 < scale_factor <= 1.0:\n",
    "        raise ValueError(\"scale_factor must be between 0.0 and 1.0.\")\n",
    "\n",
    "    original_height, original_width = image.shape[:2]\n",
    "    new_width = int(original_width * scale_factor)\n",
    "    new_height = int(original_height * scale_factor)\n",
    "    new_dimensions = (new_width, new_height)\n",
    "\n",
    "    downscaled_image = cv2.resize(\n",
    "        image,\n",
    "        new_dimensions,\n",
    "        interpolation=cv2.INTER_AREA\n",
    "    )\n",
    "\n",
    "    return downscaled_image\n",
    "\n",
    "def upsample_mask(mask: np.ndarray, original_shape: tuple) -> np.ndarray:\n",
    "    original_height, original_width = original_shape[:2]\n",
    "    target_dimensions = (original_width, original_height) # cv2 uses (width, height)\n",
    "\n",
    "    upscaled_mask = cv2.resize(\n",
    "        mask,\n",
    "        target_dimensions,\n",
    "        interpolation=cv2.INTER_NEAREST\n",
    "    )\n",
    "\n",
    "    return upscaled_mask\n",
    "\n",
    "def memory_efficient_segmentation(image, segmentation_params):\n",
    "    downsampled = downsample(image, scale_factor=segmentation_params['downsample_factor'])\n",
    "    \n",
    "    masks = cellpose_bag(downsampled)\n",
    "    del downsampled\n",
    "    \n",
    "    upsampled_masks = upsample_mask(masks, image.shape)\n",
    "    del masks\n",
    "    \n",
    "    filtered_masks = skimage.segmentation.clear_border(upsampled_masks, buffer_size=10)\n",
    "    del upsampled_masks\n",
    "    \n",
    "    return filtered_masks\n",
    "\n",
    "# spots\n",
    "def spot_tophat_correction(image, footprint):\n",
    "    corrected_spots = skimage.morphology.white_tophat(image, footprint=footprint)\n",
    "    return corrected_spots\n",
    "\n",
    "def detect_spots_spotiflow(image):\n",
    "    \"\"\"Detect spots spotiflow\"\"\"\n",
    "    model = Spotiflow.from_pretrained(\"general\")\n",
    "    points, details = model.predict(\n",
    "        img=image,\n",
    "        verbose=False\n",
    "    )\n",
    "    return points, details\n",
    "\n",
    "\n",
    "def assign_spots_to_mask(coordinates, mask):\n",
    "    if len(coordinates) == 0:\n",
    "        return []\n",
    "    \n",
    "    # Convert to numpy array if needed\n",
    "    if not isinstance(coordinates, np.ndarray):\n",
    "        coordinates = np.array(coordinates)\n",
    "    \n",
    "    roi_coords = []\n",
    "    \n",
    "    for coord in coordinates:\n",
    "        # Handle both integer and float coordinates\n",
    "        y, x = int(round(coord[0])), int(round(coord[1]))\n",
    "        \n",
    "        # Check bounds and mask\n",
    "        if (0 <= y < mask.shape[0] and \n",
    "            0 <= x < mask.shape[1] and \n",
    "            mask[y, x]):\n",
    "            roi_coords.append(coord.tolist())  # Convert back to list for consistency\n",
    "    \n",
    "    return roi_coords\n",
    "\n",
    "def calculate_roi_properties(mask, pixel_size_um):\n",
    "    \"\"\"Calculate ROI area and volume\"\"\"\n",
    "    area_pixels = np.sum(mask)\n",
    "    area_um2 = area_pixels * (pixel_size_um ** 2)\n",
    "    volume_um3 = area_um2 * thickness_um\n",
    "    return area_pixels, area_um2, volume_um3\n",
    "\n",
    "def analyze_rois_memory_efficient( masks, coords_spotiflow, pixel_size_um):\n",
    "    \"\"\"Process ROIs one at a time to minimize memory usage\"\"\"\n",
    "    num_rois = masks.max()\n",
    "    results = []\n",
    "    roi_coords_spotiflow = []\n",
    "    \n",
    "    for mask_id in range(1, num_rois + 1):\n",
    "        single_mask = (masks == mask_id)\n",
    "        \n",
    "        roi_spotiflow_coords = assign_spots_to_mask(coords_spotiflow, single_mask)\n",
    "        spot_count_spotiflow = len(roi_spotiflow_coords)\n",
    "        \n",
    "        area_pixels, area_um2, volume_um3 = calculate_roi_properties(single_mask, pixel_size_um)\n",
    "        \n",
    "        result = {\n",
    "            'ROI': mask_id,\n",
    "            'Spot_Count': spot_count_spotiflow,\n",
    "            'ROI_Area_pixels': area_pixels,\n",
    "            'ROI_Area_um2': area_um2,\n",
    "            'ROI_Volume_um3': volume_um3,\n",
    "            'Spots_per_Area': spot_count_spotiflow / area_um2 if area_um2 > 0 else 0,\n",
    "            'Spots_per_Volume': spot_count_spotiflow / volume_um3 if volume_um3 > 0 else 0\n",
    "        }\n",
    "        \n",
    "        results.append(result)\n",
    "        roi_coords_spotiflow.extend(roi_spotiflow_coords)\n",
    "        \n",
    "        del single_mask\n",
    "    \n",
    "    return results, roi_coords_spotiflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "class MicroscopyQC:\n",
    "    def __init__(self, figsize=(15, 10), dpi=300):\n",
    "        plt.ioff()\n",
    "        self.figsize = figsize\n",
    "        self.dpi = dpi\n",
    "\n",
    "    def create_qc_figure(self,\n",
    "                         segmentation_image,\n",
    "                         spot_std,\n",
    "                         coordinates,\n",
    "                         corrected_spots,\n",
    "                         masks,\n",
    "                         flow_details,\n",
    "                         condition,\n",
    "                         image_num,\n",
    "                         output_path,\n",
    "                         pixel_size_um,\n",
    "                         percentile_range=(1, 99.8),\n",
    "                         downsample_factor=8,\n",
    "                         mask_alpha=0.3):\n",
    "        \"\"\"\n",
    "        QC figure using the 'constrained' layout engine for robust, automatic spacing.\n",
    "        \"\"\"\n",
    "        # Create figure using the 'constrained' layout engine\n",
    "        # This one argument replaces plt.tight_layout() and plt.subplots_adjust()\n",
    "        fig, axes = plt.subplots(2, 3, figsize=self.figsize,\n",
    "                                 facecolor='white',\n",
    "                                 layout='constrained')\n",
    "\n",
    "        # Calculate intensity limits\n",
    "        seg_clim = tuple(np.percentile(segmentation_image[::downsample_factor, ::downsample_factor], percentile_range))\n",
    "        spot_clim = tuple(np.percentile(spot_std[::downsample_factor, ::downsample_factor], percentile_range))\n",
    "        corrected_clim = tuple(np.percentile(corrected_spots[::downsample_factor, ::downsample_factor], percentile_range))\n",
    "\n",
    "        axes = axes.flatten()\n",
    "        for ax in axes:\n",
    "            ax.axis('off')\n",
    "\n",
    "        # Panel 1: Segmentation Channel\n",
    "        axes[0].imshow(segmentation_image, cmap=\"gray\", clim=seg_clim)\n",
    "        axes[0].set_title('Segmentation Channel', fontsize=12)\n",
    "\n",
    "        # Panel 2: Spots Channel\n",
    "        axes[1].imshow(spot_std, cmap=\"magma\", clim=spot_clim)\n",
    "        axes[1].set_title('Spots Channel', fontsize=12)\n",
    "\n",
    "        # Panel 3: Spots + Detections\n",
    "        axes[2].imshow(spot_std, cmap=\"magma\", clim=spot_clim)\n",
    "        coordinates = np.array(coordinates)\n",
    "        if len(coordinates) > 0:\n",
    "            axes[2].scatter(coordinates[:, 1], coordinates[:, 0],\n",
    "                            facecolors='none', edgecolors='orange', s=10, linewidths=1)\n",
    "        axes[2].set_title(f'Detections ({len(coordinates)} spots)', fontsize=12)\n",
    "\n",
    "        # Panel 4: Segmentation + Masks\n",
    "        axes[3].imshow(segmentation_image, cmap='gray', clim=seg_clim)\n",
    "        if masks is not None:\n",
    "            mask_overlay = np.ma.masked_where(masks == 0, masks)\n",
    "            axes[3].imshow(mask_overlay, alpha=mask_alpha, cmap='tab10', vmin=1)\n",
    "        axes[3].set_title(f'Masks ({masks.max() if masks is not None else 0} ROIs)', fontsize=12)\n",
    "\n",
    "        # Panel 5: TopHat Filtered\n",
    "        axes[4].imshow(corrected_spots, cmap=\"magma\", clim=corrected_clim)\n",
    "        axes[4].set_title('TopHat Filtered', fontsize=12)\n",
    "\n",
    "        # Panel 6: Stereographic Flow\n",
    "        if flow_details is not None:\n",
    "            try:\n",
    "                flow_viz = 0.5 * (1 + getattr(flow_details, 'flow', flow_details))\n",
    "                axes[5].imshow(flow_viz)\n",
    "            except Exception as e:\n",
    "                axes[5].text(0.5, 0.5, 'No Flow Data', ha='center', va='center',\n",
    "                             transform=axes[5].transAxes, fontsize=12, color='gray')\n",
    "        axes[5].set_title('Stereographic Flow', fontsize=12)\n",
    "\n",
    "        # Add scale bar\n",
    "        if pixel_size_um > 0:\n",
    "            scalebar = ScaleBar(pixel_size_um, units='um', location='lower right',\n",
    "                                box_alpha=0.8, color='white', box_color='black')\n",
    "            axes[0].add_artist(scalebar)\n",
    "\n",
    "        # Set main title\n",
    "        fig.suptitle(f'{condition} - Image {image_num}', fontsize=16)\n",
    "\n",
    "        # Save figure\n",
    "        fig.savefig(output_path, dpi=self.dpi, bbox_inches='tight',\n",
    "                    facecolor='white', pad_inches=0.1)\n",
    "        \n",
    "        plt.close(fig)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82788d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find all .czi and .nd2 files \n",
    "nd2_files = list(raw_data_folder.glob('*.nd2'))\n",
    "czi_files = list(raw_data_folder.glob('*.czi'))\n",
    "\n",
    "# Check what files we have\n",
    "total_files = len(nd2_files) + len(czi_files)\n",
    "if total_files == 0:\n",
    "    raise FileNotFoundError(\"No .nd2 or .czi files found in raw_data folder\")\n",
    "\n",
    "# Determine file type and print summary\n",
    "if nd2_files and czi_files:\n",
    "    raise ValueError(\"Mixed file types found. Please process .nd2 and .czi files separately.\")\n",
    "elif nd2_files:\n",
    "    file_type = 'nd2'\n",
    "    files_to_process = nd2_files\n",
    "    print(f\"Found {len(nd2_files)} .nd2 files to process:\")\n",
    "    for file_path in nd2_files:\n",
    "        print(f\"  - {file_path.name}\")\n",
    "elif czi_files:\n",
    "    file_type = 'czi'\n",
    "    files_to_process = czi_files\n",
    "    print(f\"Found {len(czi_files)} .czi files to process:\")\n",
    "    for file_path in czi_files:\n",
    "        print(f\"  - {file_path.name}\")\n",
    "\n",
    "# Group CZI files by condition if needed\n",
    "if file_type == 'czi':\n",
    "    condition_groups = {}\n",
    "    for file_path in files_to_process:\n",
    "        filename = file_path.stem\n",
    "        parts = filename.split('_')\n",
    "        if len(parts) >= 2 and parts[-1].isdigit():\n",
    "            condition = '_'.join(parts[:-1])\n",
    "            field_num = int(parts[-1])\n",
    "        else:\n",
    "            condition = filename\n",
    "            field_num = 1\n",
    "        \n",
    "        if condition not in condition_groups:\n",
    "            condition_groups[condition] = []\n",
    "        condition_groups[condition].append((file_path, field_num))\n",
    "    \n",
    "    # Sort files within each condition by field number\n",
    "    for condition in condition_groups:\n",
    "        condition_groups[condition].sort(key=lambda x: x[1])\n",
    "\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c798be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "if file_type == 'nd2':\n",
    "    # Process ND2 files\n",
    "    for file_path in files_to_process:\n",
    "        condition = file_path.stem\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {condition}...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        try:\n",
    "            array = nd2.imread(file_path, xarray=True, dask=True)\n",
    "            with nd2.ND2File(file_path) as nd2_file:\n",
    "                pixel_size_um = nd2_file.voxel_size().x\n",
    "                num_positions = nd2_file.sizes['P']\n",
    "                \n",
    "                for p in tqdm(range(num_positions), desc=f\"Processing {condition}\"):\n",
    "                    print(f\"\\n  Field of view {p+1}/{num_positions}\")\n",
    "                    \n",
    "                    # Load and process one field of view\n",
    "                    seg_image, spots_image = process_field_of_view(array, p, channels_params)\n",
    "                    \n",
    "                    # Common processing starts here\n",
    "                    corrected_spots = skimage.morphology.white_tophat(spots_image, footprint=footprint)\n",
    "                    \n",
    "                    # Segmentation\n",
    "                    print(\"    Running segmentation...\")\n",
    "                    masks = memory_efficient_segmentation(seg_image, segmentation_params)\n",
    "                    num_rois = masks.max()\n",
    "                    print(f\"    Found {num_rois} gel bags\")\n",
    "                    \n",
    "                    if num_rois == 0:\n",
    "                        print(\"    â ï¸ No ROIs detected in this field of view, skipping analysis and QC.\")\n",
    "                        continue\n",
    "                    \n",
    "                    # Count Spots\n",
    "                    coords_spotiflow, details = detect_spots_spotiflow(corrected_spots)\n",
    "                    \n",
    "                    # Analyze ROIs\n",
    "                    roi_results, coords_spotiflow = analyze_rois_memory_efficient(masks, coords_spotiflow, pixel_size_um)\n",
    "                    \n",
    "                    # Add metadata to results\n",
    "                    for result in roi_results:\n",
    "                        result.update({\n",
    "                            'Experiment': experiment_folder.name,\n",
    "                            'Condition': condition,\n",
    "                            'Image_Number': p + 1\n",
    "                        })\n",
    "                    \n",
    "                    results.extend(roi_results)\n",
    "                    \n",
    "                    # Create QC figure\n",
    "                    qc_figure_path = figures_folder / f\"{condition}_image_{p+1:03d}_QC.png\"\n",
    "                    qc = MicroscopyQC(figsize=(10, 8), dpi=300)\n",
    "                    qc.create_qc_figure(segmentation_image=seg_image,\n",
    "                                        spot_std=spots_image,\n",
    "                                        coordinates=coords_spotiflow,\n",
    "                                        corrected_spots=corrected_spots,\n",
    "                                        masks=masks,\n",
    "                                        flow_details=details.flow,\n",
    "                                        condition=condition,\n",
    "                                        image_num=p + 1,\n",
    "                                        output_path=qc_figure_path,\n",
    "                                        pixel_size_um=pixel_size_um\n",
    "                                    )\n",
    "                    \n",
    "                    total_spots = len(coords_spotiflow)\n",
    "                    print(f\"    Average spots detected: {total_spots / num_rois}\")\n",
    "                    print(f\"    QC figure saved: {qc_figure_path.name}\")\n",
    "                    \n",
    "                    # Force garbage collection\n",
    "                    del seg_image, spots_image, corrected_spots, masks, roi_results, coords_spotiflow, details\n",
    "                    gc.collect()\n",
    "                    \n",
    "        except Exception as e:\n",
    "            print(f\"â Error processing {condition}: {str(e)}\")\n",
    "            warnings.warn(f\"Failed to process {condition}: {str(e)}\")\n",
    "\n",
    "else:  # file_type == 'czi'\n",
    "    # Process CZI files\n",
    "    for condition, file_list in condition_groups.items():\n",
    "        print(f\"\\n{'='*50}\")\n",
    "        print(f\"Processing {condition}...\")\n",
    "        print(f\"{'='*50}\")\n",
    "        \n",
    "        for file_path, field_num in tqdm(file_list, desc=f\"Processing {condition}\"):\n",
    "            print(f\"\\n  Field of view {field_num}\")\n",
    "            \n",
    "            try:\n",
    "                # Load CZI file - adjust channel numbers as needed\n",
    "                czi = CziFile(file_path)\n",
    "                \n",
    "                seg_image, seg_info = czi.read_image(C=channels_params['brightfield'])\n",
    "                spots_image, spots_info = czi.read_image(C=channels_params['spots'])\n",
    "                \n",
    "                seg_image = np.squeeze(seg_image)\n",
    "                spots_image = np.squeeze(spots_image)\n",
    "                \n",
    "                seg_image = np.std(seg_image, axis=0)\n",
    "                del seg_info\n",
    "    \n",
    "                spots_image = np.std(spots_image, axis=0)\n",
    "                del spots_info\n",
    "                \n",
    "                img = AICSImage(file_path)\n",
    "                pixel_size_um = img.physical_pixel_sizes.X\n",
    "                \n",
    "                # Common processing starts here (same as ND2)\n",
    "                corrected_spots = skimage.morphology.white_tophat(spots_image, footprint=footprint)\n",
    "                \n",
    "                # Segmentation\n",
    "                print(\"    Running segmentation...\")\n",
    "                masks = memory_efficient_segmentation(seg_image, segmentation_params)\n",
    "                num_rois = masks.max()\n",
    "                print(f\"    Found {num_rois} gel bags\")\n",
    "                \n",
    "                if num_rois == 0:\n",
    "                    print(\"    â ï¸ No ROIs detected in this field of view, skipping analysis and QC.\")\n",
    "                    continue\n",
    "                \n",
    "                # Count Spots\n",
    "                coords_spotiflow, details = detect_spots_spotiflow(corrected_spots)\n",
    "                \n",
    "                # Analyze ROIs\n",
    "                roi_results, coords_spotiflow = analyze_rois_memory_efficient(masks, coords_spotiflow, pixel_size_um)\n",
    "                \n",
    "                # Add metadata to results\n",
    "                for result in roi_results:\n",
    "                    result.update({\n",
    "                        'Experiment': experiment_folder.name,\n",
    "                        'Condition': condition,\n",
    "                        'Image_Number': field_num\n",
    "                    })\n",
    "                \n",
    "                results.extend(roi_results)\n",
    "                \n",
    "                # Create QC figure\n",
    "                qc_figure_path = figures_folder / f\"{condition}_image_{field_num:03d}_QC.png\"\n",
    "                qc = MicroscopyQC(figsize=(10, 8), dpi=300)\n",
    "                qc.create_qc_figure(segmentation_image=seg_image,\n",
    "                                    spot_std=spots_image,\n",
    "                                    coordinates=coords_spotiflow,\n",
    "                                    corrected_spots=corrected_spots,\n",
    "                                    masks=masks,\n",
    "                                    flow_details=details.flow,\n",
    "                                    condition=condition,\n",
    "                                    image_num=field_num,\n",
    "                                    output_path=qc_figure_path,\n",
    "                                    pixel_size_um=pixel_size_um\n",
    "                                )\n",
    "                \n",
    "                total_spots = len(coords_spotiflow)\n",
    "                print(f\"    Average spots detected: {total_spots / num_rois}\")\n",
    "                print(f\"    QC figure saved: {qc_figure_path.name}\")\n",
    "                \n",
    "                # Force garbage collection\n",
    "                del seg_image, spots_image, corrected_spots, masks, roi_results, coords_spotiflow, details\n",
    "                gc.collect()\n",
    "                \n",
    "            except Exception as e:\n",
    "                print(f\"â Error processing {file_path.name}: {str(e)}\")\n",
    "                warnings.warn(f\"Failed to process {file_path.name}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nð Processing complete! Analyzed {len(results)} ROIs total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95016559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save results to files\n",
    "if not results:\n",
    "    print(\"â No results to save\")\n",
    "else:\n",
    "    df = pd.DataFrame(results )\n",
    "    \n",
    "    # Filter out ROIs with area < 3000 ÂµmÂ²\n",
    "    df = df[df['ROI_Area_um2'] >= 3000]\n",
    "    \n",
    "    # Save as CSV\n",
    "    csv_path = processed_data_folder / f\"{experiment_folder.name}_results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save as Excel with multiple sheets\n",
    "    excel_path = processed_data_folder / f\"{experiment_folder.name}_results.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='All_Data', index=False)\n",
    "        \n",
    "        # Summary by condition\n",
    "        summary = df.groupby('Condition').agg({\n",
    "            'Spot_Count': ['count', 'mean', 'std', 'sum'],\n",
    "            'ROI_Area_um2': ['mean', 'std'],\n",
    "            'Spots_per_Area': ['mean', 'std'],\n",
    "            'Spots_per_Volume': ['mean', 'std']\n",
    "        }).round(3)\n",
    "        \n",
    "        summary.columns = ['_'.join(col).strip() for col in summary.columns]\n",
    "        summary.reset_index().to_excel(writer, sheet_name='Summary_by_Condition', index=False)\n",
    "    \n",
    "    print(f\"â Results saved to:\")\n",
    "    print(f\"   ð CSV: {csv_path}\")\n",
    "    print(f\"   ð Excel: {excel_path}\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(f\"\\nð Quick Statistics:\")\n",
    "    print(f\"   Total ROIs analyzed: {len(df)}\")\n",
    "    print(f\"   Conditions: {df['Condition'].nunique()}\")\n",
    "    print(f\"   Total spots detected: {df['Spot_Count'].sum()}\")\n",
    "    print(f\"   Average spots per ROI: {df['Spot_Count'].mean():.1f} Â± {df['Spot_Count'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c40b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Preview results\n",
    "# Display first few rows and basic info\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    # Filter out ROIs with area < 3000 ÂµmÂ²\n",
    "    df = df[df['ROI_Area_um2'] >= 3000]\n",
    "    print(\"ð Results Preview:\")\n",
    "    print(df.head(5))\n",
    "    \n",
    "    print(f\"\\nð Summary by Condition:\")\n",
    "    condition_summary = df.groupby('Condition').agg({\n",
    "        'ROI': 'count',\n",
    "        'Spot_Count': ['mean', 'std'],\n",
    "        'ROI_Area_um2': ['mean', 'std'],\n",
    "        'Spots_per_Area': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    condition_summary.columns = ['_'.join(col).strip() for col in condition_summary.columns]\n",
    "    print(condition_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99825272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create summary analysis figures\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    # Filter out ROIs with area < 3000 ÂµmÂ²\n",
    "    df = df[df['ROI_Area_um2'] >= 3000]\n",
    "    \n",
    "    # Calculate sample sizes for each condition\n",
    "    sample_sizes = df.groupby('Condition').size()\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Figure 1: Spot counts by condition\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Function to add sample size annotations\n",
    "    def add_n_annotations(ax, data_col, group_col='Condition'):\n",
    "        \"\"\"Add sample size annotations to boxplot\"\"\"\n",
    "        # Get unique conditions and their positions\n",
    "        conditions = df[group_col].unique()\n",
    "        \n",
    "        for i, condition in enumerate(conditions):\n",
    "            n = len(df[df[group_col] == condition])\n",
    "            # Add annotation to the right of each boxplot\n",
    "            ax.text(ax.get_xlim()[1] * 0.98, i, f'n={n}', \n",
    "                   verticalalignment='center', \n",
    "                   horizontalalignment='right',\n",
    "                   fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Spot count distribution\n",
    "    sns.boxplot(data=df, y='Condition', x='Spot_Count', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Spot Count Distribution by Condition')\n",
    "    axes[0, 0].set_ylabel('')\n",
    "    add_n_annotations(axes[0, 0], 'Spot_Count')\n",
    "    \n",
    "    # ROI area distribution\n",
    "    sns.boxplot(data=df, y='Condition', x='ROI_Area_um2', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('ROI Area Distribution by Condition')\n",
    "    axes[0, 1].set_xlabel('ROI Area (Î¼mÂ²)')\n",
    "    axes[0, 1].set_ylabel('')\n",
    "    add_n_annotations(axes[0, 1], 'ROI_Area_um2')\n",
    "    \n",
    "    # Spots per area\n",
    "    sns.boxplot(data=df, y='Condition', x='Spots_per_Area', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Spots per Area by Condition')\n",
    "    axes[1, 0].set_xlabel('Spots per Î¼mÂ²')\n",
    "    axes[1, 0].set_ylabel('')\n",
    "    add_n_annotations(axes[1, 0], 'Spots_per_Area')\n",
    "    \n",
    "    # Spots per volume\n",
    "    sns.boxplot(data=df, y='Condition', x='Spots_per_Volume', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Spots per Volume by Condition')\n",
    "    axes[1, 1].set_xlabel('Spots per Î¼mÂ³')\n",
    "    axes[1, 1].set_ylabel('')\n",
    "    add_n_annotations(axes[1, 1], 'Spots_per_Volume')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    summary_path = figures_folder / 'Summary_Analysis.png'\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Summary figure saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3099ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create correlation analysis figures\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    # Filter out ROIs with area < 3000 ÂµmÂ²\n",
    "    df = df[df['ROI_Area_um2'] >= 3000]\n",
    "    \n",
    "    # Figure 2: Correlation plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(8, 5))\n",
    "    \n",
    "    # Spot count vs ROI area\n",
    "    sns.scatterplot(data=df, x='ROI_Area_um2', y='Spot_Count', hue='Condition', ax=ax)\n",
    "    ax.set_title('Spot Count vs ROI Area')\n",
    "    ax.set_xlabel('ROI Area (Î¼mÂ²)')\n",
    "    ax.set_ylabel('Spot Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    correlation_path = figures_folder / 'Correlation_Analysis.png'\n",
    "    plt.savefig(correlation_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"â Correlation figure saved: {correlation_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose-bags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
