{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1f29d9c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "Welcome to CellposeSAM, cellpose v\n",
      "cellpose version: \t4.0.5 \n",
      "platform:       \twin32 \n",
      "python version: \t3.11.13 \n",
      "torch version:  \t2.7.1+cu128! The neural network component of\n",
      "CPSAM is much larger than in previous versions and CPU excution is slow. \n",
      "We encourage users to use GPU/MPS if available. \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Cell 1: Import libraries\n",
    "import numpy as np\n",
    "from cellpose import models\n",
    "import skimage\n",
    "import nd2\n",
    "import xarray\n",
    "\n",
    "# figures\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib_scalebar.scalebar import ScaleBar\n",
    "\n",
    "# plotting and processing\n",
    "from tqdm.notebook import tqdm\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import os\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import openpyxl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f9e0b54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 2: Configuration and setup\n",
    "# EXPERIMENT CONFIGURATION\n",
    "\n",
    "experiment_folder = Path.cwd().parent \n",
    "raw_data_folder = experiment_folder / 'raw_data'\n",
    "figures_folder = experiment_folder / 'figures'\n",
    "processed_data_folder = experiment_folder / 'processed_data'\n",
    "\n",
    "os.environ[\"CELLPOSE_LOCAL_MODELS_PATH\"] = str(experiment_folder.parent / '_pipeline_assets/cellpose_models/') # location of cellpose models\n",
    "flatfiled_map_folder = figures_folder\n",
    "\n",
    "# Create output folders if they don't exist\n",
    "figures_folder.mkdir(exist_ok=True)\n",
    "processed_data_folder.mkdir(exist_ok=True)\n",
    "\n",
    "# ANALYSIS PARAMETERS\n",
    "thickness_um = 20\n",
    "\n",
    "# Channel order\n",
    "channels_params = {\n",
    "    'brightfield': 0,\n",
    "    'spots': 1,\n",
    "    'bags': 2\n",
    "}\n",
    "\n",
    "# Channel used for spot acquisition\n",
    "spot_channel_params = {\n",
    "    'FAM': False,\n",
    "    'TAMRA': True\n",
    "}\n",
    "\n",
    "# Segmentation parameters\n",
    "segmentation_params = {\n",
    "    'diameter': 676,\n",
    "    'model_name': 'cpsam_20x_downsampeled_20250630',\n",
    "    'gpu': True\n",
    "}\n",
    "\n",
    "# Spot detection parameters\n",
    "spot_detection_params = {\n",
    "    'min_distance': 3,\n",
    "    'threshold_abs': 800\n",
    "}\n",
    "\n",
    "# Background correction\n",
    "background_sigma_params = {\n",
    "    \"segmentation_sigma\": 40,\n",
    "    \"spot_sigma\": 100\n",
    "}\n",
    "\n",
    "print(f\"Experiment folder: {experiment_folder}\")\n",
    "print(f\"Gel thickness: {thickness_um} Œºm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1a189a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Define analysis functions\n",
    "def gaussian_background_correction(image, sigma):\n",
    "    \"\"\"Estimate background with heavy gaussian blur\"\"\"\n",
    "    background = skimage.filters.gaussian(image.astype(np.float32), sigma=sigma)\n",
    "    corrected = image.astype(np.float32) - background\n",
    "    return corrected\n",
    "\n",
    "def get_flatfield_files(spot_channel_params):\n",
    "    \"\"\"Select appropriate flatfield .nd2 files based on channel parameters\"\"\"\n",
    "    flatfield_files = {\n",
    "    'BF': flatfiled_map_folder / 'flatfield_BF.nd2',\n",
    "    'FAM': flatfiled_map_folder / 'flatfield_FAM.nd2',\n",
    "    'TAMRA': flatfiled_map_folder / 'flatfield_TAMRA.nd2'\n",
    "    }\n",
    "    \n",
    "    # Find which channel is active for spot detection\n",
    "    active_channels = [channel for channel, is_active in spot_channel_params.items() if is_active]\n",
    "    active_channel = active_channels[0]\n",
    "    \n",
    "    return {\n",
    "        'segmentation': flatfield_files['BF'],\n",
    "        'spot_detection': flatfield_files[active_channel]\n",
    "    }    \n",
    "\n",
    "def flatfield_correction(image, flatfield_image):\n",
    "    \"\"\"Flatfield correction based on previously taken flatfield images\"\"\"\n",
    "    FF_image = nd2.imread(flatfield_image)\n",
    "    mean_FF_BF = np.mean(FF_image)\n",
    "    normalised_FF_BF = FF_image / mean_FF_BF\n",
    "    corrected_image = image / normalised_FF_BF\n",
    "    return corrected_image\n",
    "\n",
    "def max_project_xarray(array):\n",
    "    \"\"\"Maximum projection of single xarray channel\"\"\"\n",
    "    return np.max(array.values, axis=0)\n",
    "\n",
    "def cellpose_bag(image):\n",
    "    \"\"\"Run bag pretrained cellpose SAM\"\"\"\n",
    "    model = models.CellposeModel(\n",
    "        gpu=segmentation_params['gpu'],\n",
    "        pretrained_model=segmentation_params['model_name']\n",
    "    )\n",
    "    \n",
    "    masks, flows, styles = model.eval(\n",
    "        image,\n",
    "        diameter=segmentation_params['diameter']\n",
    "    )\n",
    "    return masks\n",
    "\n",
    "def detect_spots(image, mask):\n",
    "    \"\"\"Detect spots within a single mask\"\"\"\n",
    "    masked_spots = image * mask\n",
    "    coords = skimage.feature.peak_local_max(\n",
    "        masked_spots,\n",
    "        min_distance=spot_detection_params['min_distance'],\n",
    "        threshold_abs=spot_detection_params['threshold_abs']\n",
    "    )\n",
    "    return coords\n",
    "\n",
    "def calculate_roi_properties(mask, pixel_size_um):\n",
    "    \"\"\"Calculate ROI area and volume\"\"\"\n",
    "    area_pixels = np.sum(mask)\n",
    "    area_um2 = area_pixels * (pixel_size_um ** 2)\n",
    "    volume_um3 = area_um2 * thickness_um\n",
    "    return area_pixels, area_um2, volume_um3\n",
    "\n",
    "print(\"Analysis functions defined ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9600ccc2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 4: Quality control figure function\n",
    "def create_qc_figure(image_seg, image_spots, masks, all_coords, condition, image_num, save_path, pixel_size_um):\n",
    "    \"\"\"Create quality control figure\"\"\"\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(8, 10))\n",
    "    \n",
    "    # Original segmentation image\n",
    "    axes[0, 0].imshow(image_seg, cmap='gray')\n",
    "    axes[0, 0].set_title('Segmentation Channel')\n",
    "    axes[0, 0].axis('off')\n",
    "    \n",
    "    # Segmentation with masks overlay\n",
    "    axes[0, 1].imshow(image_seg, cmap='gray')\n",
    "    axes[0, 1].imshow(masks, alpha=0.3, cmap='tab10')\n",
    "    axes[0, 1].set_title(f'Segmentation + Masks ({masks.max()} ROIs)')\n",
    "    axes[0, 1].axis('off')\n",
    "    \n",
    "    # Spots channel\n",
    "    axes[1, 0].imshow(image_spots, cmap='twilight_shifted')\n",
    "    axes[1, 0].set_title('Spots Channel')\n",
    "    axes[1, 0].axis('off')\n",
    "    \n",
    "    # Spots with detections\n",
    "    axes[1, 1].imshow(image_spots, cmap='twilight_shifted')\n",
    "    if len(all_coords) > 0:\n",
    "        all_coords_array = np.vstack(all_coords)\n",
    "        axes[1, 1].scatter(all_coords_array[:, 1], all_coords_array[:, 0], \n",
    "                         s=10, c='red', marker='x', alpha=0.8)\n",
    "    axes[1, 1].set_title(f'Spots + Detections ({len(all_coords)} total)')\n",
    "    axes[1, 1].axis('off')\n",
    "    \n",
    "    # Add scale bar to first subplot\n",
    "    scalebar = ScaleBar(pixel_size_um, units='um', location='lower right')\n",
    "    axes[0, 0].add_artist(scalebar)\n",
    "    \n",
    "    plt.suptitle(f'{condition} - Image {image_num}', fontsize=14)\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "\n",
    "print(\"QC figure function defined ‚úì\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82788d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 5: Find and list files to process\n",
    "# Assign appropriate flatfield images\n",
    "flatfields = get_flatfield_files(spot_channel_params)\n",
    "\n",
    "# Find all .nd2 files\n",
    "nd2_files = list(raw_data_folder.glob('*.nd2'))\n",
    "\n",
    "if not nd2_files:\n",
    "    raise FileNotFoundError(\"No .nd2 files found in raw_data folder\")\n",
    "\n",
    "print(f\"Found {len(nd2_files)} .nd2 files to process:\")\n",
    "for file_path in nd2_files:\n",
    "    print(f\"  - {file_path.name}\")\n",
    "\n",
    "# Initialize results storage\n",
    "results = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c798be4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 6: Main processing loop\n",
    "for file_path in nd2_files:\n",
    "    condition = file_path.stem  # filename without extension\n",
    "    print(f\"\\n{'='*50}\")\n",
    "    print(f\"Processing {condition}...\")\n",
    "    print(f\"{'='*50}\")\n",
    "    \n",
    "    try:\n",
    "        # Read image\n",
    "        array = nd2.imread(file_path, xarray=True)\n",
    "        print(f\"Image dimensions: {array.sizes}\")\n",
    "        with nd2.ND2File(file_path) as nd2_file:\n",
    "            pixel_size_um =nd2_file.voxel_size().x \n",
    "        \n",
    "        # Process each field of view\n",
    "        for p in tqdm(range(array.sizes['P']), desc=f\"Processing {condition}\"):\n",
    "            print(f\"\\n  Field of view {p+1}/{array.sizes['P']}\")\n",
    "            \n",
    "            # Preprocessing\n",
    "            image_segmentation = array.isel(P=p, C=channels_params['brightfield'])\n",
    "            image_segmentation_max = max_project_xarray(image_segmentation)\n",
    "            corrected_segmentation = flatfield_correction(image_segmentation_max, flatfields['segmentation'])\n",
    "            \n",
    "            image_spots = array.isel(P=p, C=channels_params['spots'])\n",
    "            image_spots_max = max_project_xarray(image_spots)\n",
    "            corrected_spots = flatfield_correction(image_spots_max, flatfields['spot_detection'])\n",
    "            \n",
    "            # Segmentation\n",
    "            print(\"    Running segmentation...\")\n",
    "            masks = cellpose_bag(corrected_segmentation)\n",
    "            filtered_masks = skimage.segmentation.clear_border(masks, buffer_size=25)\n",
    "            \n",
    "            num_rois = filtered_masks.max()\n",
    "            print(f\"    Found {num_rois} gel bags\")\n",
    "            \n",
    "            # Spot detection and analysis\n",
    "            all_coords_for_qc = []\n",
    "            \n",
    "            for mask_id in range(1, num_rois + 1):\n",
    "                single_mask = filtered_masks == mask_id\n",
    "                \n",
    "                # Detect spots\n",
    "                coords = detect_spots(corrected_spots, single_mask)\n",
    "                spot_count = len(coords)\n",
    "                \n",
    "                # Calculate ROI properties\n",
    "                area_pixels, area_um2, volume_um3 = calculate_roi_properties(single_mask, pixel_size_um)\n",
    "                \n",
    "                # Calculate densities\n",
    "                spots_per_area = spot_count / area_um2 if area_um2 > 0 else 0\n",
    "                spots_per_volume = spot_count / volume_um3 if volume_um3 > 0 else 0\n",
    "                \n",
    "                # Store results\n",
    "                result = {\n",
    "                    'Experiment': experiment_folder.name,\n",
    "                    'Condition': condition,\n",
    "                    'Image_Number': p + 1,\n",
    "                    'ROI': mask_id,\n",
    "                    'Spot_Count': spot_count,\n",
    "                    'ROI_Area_pixels': area_pixels,\n",
    "                    'ROI_Area_um2': area_um2,\n",
    "                    'ROI_Volume_um3': volume_um3,\n",
    "                    'Spots_per_Area': spots_per_area,\n",
    "                    'Spots_per_Volume': spots_per_volume\n",
    "                }\n",
    "                \n",
    "                results.append(result)\n",
    "                all_coords_for_qc.extend(coords)\n",
    "            \n",
    "            # Create QC figure\n",
    "            qc_figure_path = figures_folder / f\"{condition}_image_{p+1:03d}_QC.png\"\n",
    "            create_qc_figure(\n",
    "                corrected_segmentation, corrected_spots, filtered_masks,\n",
    "                all_coords_for_qc, condition, p+1, qc_figure_path, pixel_size_um\n",
    "            )\n",
    "            \n",
    "            total_spots = len(all_coords_for_qc)\n",
    "            print(f\"    Average spots detected: {total_spots / num_rois}\")\n",
    "            print(f\"    QC figure saved: {qc_figure_path.name}\")\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error processing {condition}: {str(e)}\")\n",
    "        warnings.warn(f\"Failed to process {condition}: {str(e)}\")\n",
    "\n",
    "print(f\"\\nüéâ Processing complete! Analyzed {len(results)} ROIs total.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95016559",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 7: Save results to files\n",
    "if not results:\n",
    "    print(\"‚ùå No results to save\")\n",
    "else:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Save as CSV\n",
    "    csv_path = processed_data_folder / f\"{experiment_folder.name}_results.csv\"\n",
    "    df.to_csv(csv_path, index=False)\n",
    "    \n",
    "    # Save as Excel with multiple sheets\n",
    "    excel_path = processed_data_folder / f\"{experiment_folder.name}_results.xlsx\"\n",
    "    with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:\n",
    "        df.to_excel(writer, sheet_name='All_Data', index=False)\n",
    "        \n",
    "        # Summary by condition\n",
    "        summary = df.groupby('Condition').agg({\n",
    "            'Spot_Count': ['count', 'mean', 'std', 'sum'],\n",
    "            'ROI_Area_um2': ['mean', 'std'],\n",
    "            'Spots_per_Area': ['mean', 'std'],\n",
    "            'Spots_per_Volume': ['mean', 'std']\n",
    "        }).round(3)\n",
    "        \n",
    "        summary.columns = ['_'.join(col).strip() for col in summary.columns]\n",
    "        summary.reset_index().to_excel(writer, sheet_name='Summary_by_Condition', index=False)\n",
    "    \n",
    "    print(f\"‚úÖ Results saved to:\")\n",
    "    print(f\"   üìÑ CSV: {csv_path}\")\n",
    "    print(f\"   üìä Excel: {excel_path}\")\n",
    "    \n",
    "    # Display basic statistics\n",
    "    print(f\"\\nüìà Quick Statistics:\")\n",
    "    print(f\"   Total ROIs analyzed: {len(df)}\")\n",
    "    print(f\"   Conditions: {df['Condition'].nunique()}\")\n",
    "    print(f\"   Total spots detected: {df['Spot_Count'].sum()}\")\n",
    "    print(f\"   Average spots per ROI: {df['Spot_Count'].mean():.1f} ¬± {df['Spot_Count'].std():.1f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c40b82",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 8: Preview results\n",
    "# Display first few rows and basic info\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    print(\"üìã Results Preview:\")\n",
    "    print(df.head(5))\n",
    "    \n",
    "    print(f\"\\nüìä Summary by Condition:\")\n",
    "    condition_summary = df.groupby('Condition').agg({\n",
    "        'ROI': 'count',\n",
    "        'Spot_Count': ['mean', 'std'],\n",
    "        'ROI_Area_um2': ['mean', 'std'],\n",
    "        'Spots_per_Area': ['mean', 'std']\n",
    "    }).round(3)\n",
    "    condition_summary.columns = ['_'.join(col).strip() for col in condition_summary.columns]\n",
    "    print(condition_summary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99825272",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 9: Create summary analysis figures\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Calculate sample sizes for each condition\n",
    "    sample_sizes = df.groupby('Condition').size()\n",
    "    \n",
    "    # Set up the plotting style\n",
    "    plt.style.use('default')\n",
    "    sns.set_palette(\"husl\")\n",
    "    \n",
    "    # Figure 1: Spot counts by condition\n",
    "    fig, axes = plt.subplots(2, 2, figsize=(15, 12))\n",
    "    \n",
    "    # Function to add sample size annotations\n",
    "    def add_n_annotations(ax, group_col='Condition'):\n",
    "        \"\"\"Add sample size annotations to boxplot\"\"\"\n",
    "        # Get unique conditions and their positions\n",
    "        conditions = df[group_col].unique()\n",
    "        \n",
    "        for i, condition in enumerate(conditions):\n",
    "            n = len(df[df[group_col] == condition])\n",
    "            # Add annotation to the right of each boxplot\n",
    "            ax.text(ax.get_xlim()[1] * 0.98, i, f'n={n}', \n",
    "                   verticalalignment='center', \n",
    "                   horizontalalignment='right',\n",
    "                   fontweight='bold',\n",
    "                   bbox=dict(boxstyle='round,pad=0.3', facecolor='white', alpha=0.8))\n",
    "    \n",
    "    # Spot count distribution\n",
    "    sns.boxplot(data=df, y='Condition', x='Spot_Count', ax=axes[0, 0])\n",
    "    axes[0, 0].set_title('Spot Count Distribution by Condition')\n",
    "    axes[0, 0].set_ylabel('')\n",
    "    add_n_annotations(axes[0, 0], 'Spot_Count')\n",
    "    \n",
    "    # ROI area distribution\n",
    "    sns.boxplot(data=df, y='Condition', x='ROI_Area_um2', ax=axes[0, 1])\n",
    "    axes[0, 1].set_title('ROI Area Distribution by Condition')\n",
    "    axes[0, 1].set_xlabel('ROI Area (Œºm¬≤)')\n",
    "    axes[0, 1].set_ylabel('')\n",
    "    add_n_annotations(axes[0, 1], 'ROI_Area_um2')\n",
    "    \n",
    "    # Spots per area\n",
    "    sns.boxplot(data=df, y='Condition', x='Spots_per_Area', ax=axes[1, 0])\n",
    "    axes[1, 0].set_title('Spots per Area by Condition')\n",
    "    axes[1, 0].set_xlabel('Spots per Œºm¬≤')\n",
    "    axes[1, 0].set_ylabel('')\n",
    "    add_n_annotations(axes[1, 0], 'Spots_per_Area')\n",
    "    \n",
    "    # Spots per volume\n",
    "    sns.boxplot(data=df, y='Condition', x='Spots_per_Volume', ax=axes[1, 1])\n",
    "    axes[1, 1].set_title('Spots per Volume by Condition')\n",
    "    axes[1, 1].set_xlabel('Spots per Œºm¬≥')\n",
    "    axes[1, 1].set_ylabel('')\n",
    "    add_n_annotations(axes[1, 1], 'Spots_per_Volume')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    summary_path = figures_folder / 'Summary_Analysis.png'\n",
    "    plt.savefig(summary_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Summary figure saved: {summary_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d3099ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 10: Create correlation analysis figures\n",
    "if results:\n",
    "    df = pd.DataFrame(results)\n",
    "    \n",
    "    # Figure 2: Correlation plot\n",
    "    fig, ax = plt.subplots(1, 1, figsize=(6, 5))\n",
    "    \n",
    "    # Spot count vs ROI area\n",
    "    sns.scatterplot(data=df, x='ROI_Area_um2', y='Spot_Count', hue='Condition', ax=ax)\n",
    "    ax.set_title('Spot Count vs ROI Area')\n",
    "    ax.set_xlabel('ROI Area (Œºm¬≤)')\n",
    "    ax.set_ylabel('Spot Count')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    correlation_path = figures_folder / 'Correlation_Analysis.png'\n",
    "    plt.savefig(correlation_path, dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    print(f\"‚úÖ Correlation figure saved: {correlation_path}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cellpose-bags",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
